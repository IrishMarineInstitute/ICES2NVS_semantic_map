{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import toolboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display to width of screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Import toolboxes\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from unidecode import unidecode\n",
    "import urllib\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import datetime\n",
    "\n",
    "# Set Pandas DataFrame to resize to display full text\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions used by the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xstr(s):\n",
    "    \"\"\"Function to remove non-ASCII characters from NVS results\"\"\"\n",
    "    if s is None:\n",
    "        return ''\n",
    "    return str(unidecode(s))\n",
    "\n",
    "def sparql_nvs_json(s):\n",
    "    \"\"\"Function to input a SPARQL query (s) into the NVS SPARQL endpoint\"\"\"\n",
    "    sparql = SPARQLWrapper(\"http://vocab.nerc.ac.uk/sparql/sparql\")\n",
    "    sparql.setQuery(s)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    r = sparql.query().convert()\n",
    "    return r\n",
    "\n",
    "def S27_map():\n",
    "    \"\"\"Function to get NVS:S27 chemical substrances which have CAS numbers as a published mapping\"\"\"\n",
    "    s =  \"\"\"PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "            PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "                \n",
    "            select ?codval ?prefLabel ?casurl\n",
    "            where {\n",
    "            <http://vocab.nerc.ac.uk/collection/S27/current/> skos:member ?url .\n",
    "            ?url skos:notation ?codval .\n",
    "            ?url skos:prefLabel ?prefLabel .\n",
    "            ?url owl:deprecated 'false' .\n",
    "            ?url owl:sameAs ?casurl .\n",
    "            FILTER(regex(str(?casurl), \"https://chem.nlm.nih.gov/chemidplus/rn/\", \"i\"))\n",
    "            }\"\"\"                \n",
    "    r = sparql_nvs_json(s)    \n",
    "    list = []\n",
    "    for i in range(0,len(r['results']['bindings'])):\n",
    "        a = xstr(r['results']['bindings'][i]['codval']['value'].replace('SDN:S27::',''))\n",
    "        b = xstr(r['results']['bindings'][i]['prefLabel']['value'])\n",
    "        c = xstr(r['results']['bindings'][i]['casurl']['value'].replace('http://chem.sis.nlm.nih.gov/chemidplus/rn/',''))\n",
    "        list.append([a,b,c])\n",
    "    return list\n",
    "\n",
    "def taxon_map(spcs,aphia):\n",
    "    \"\"\"Function to get NVS:S25 TAXON from an AphiaID and species\"\"\"\n",
    "    s =  \"\"\"PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "            PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "                \n",
    "            select ?prefLabel\n",
    "            where {\n",
    "                    <http://vocab.nerc.ac.uk/collection/S25/current/> skos:member ?url .\n",
    "                    ?url skos:notation ?codval .\n",
    "                    ?url skos:prefLabel ?prefLabel .\n",
    "                    ?url owl:deprecated 'false' .\n",
    "                    FILTER(CONTAINS(?prefLabel,'%s')).\n",
    "                    FILTER(CONTAINS(?prefLabel,'WoRMS %s)')).\n",
    "                }\"\"\" % (spcs, aphia)\n",
    "    r = sparql_nvs_json(s)\n",
    "    list = []\n",
    "    if len(r['results']['bindings']) == 0:\n",
    "        a = 'Not available'\n",
    "    else:\n",
    "        label_list = []\n",
    "        for i in range(0,len(r['results']['bindings'])):\n",
    "            h = re.sub('\\s\\[.*?\\]' ,'',xstr(r['results']['bindings'][i]['prefLabel']['value']))\n",
    "            if h not in label_list:\n",
    "                label_list.append(h)\n",
    "                a = h\n",
    "    list.append([a, aphia])\n",
    "    return list\n",
    "\n",
    "def S25_lookup(spcs,aphia,label):\n",
    "    \"\"\"Function to get NVS:S25 codval from the generated preflabel, if it exists\"\"\"\n",
    "    s =  \"\"\"PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "            PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "                \n",
    "            select ?codval ?prefLabel\n",
    "            where {\n",
    "            <http://vocab.nerc.ac.uk/collection/S25/current/> skos:member ?url .\n",
    "            ?url skos:notation ?codval .\n",
    "            ?url skos:prefLabel ?prefLabel .\n",
    "            ?url owl:deprecated 'false' .\n",
    "            FILTER(CONTAINS(?prefLabel,'%s (')).\n",
    "            FILTER(CONTAINS(?prefLabel,'WoRMS %s')).\n",
    "            FILTER(STRENDS(?prefLabel,'%s')).\n",
    "            }\"\"\" % (spcs, aphia, label)\n",
    "    r = sparql_nvs_json(s)\n",
    "    list = []\n",
    "    if len(r['results']['bindings']) == 0:\n",
    "        a = 'No S25 term. Needs adding to NVS'\n",
    "        b = \"%s (ITIS: ?????: WoRMS %s) %s\" % (spcs, aphia, label)\n",
    "    else:\n",
    "        for i in range(0,len(r['results']['bindings'])):\n",
    "            a = xstr(r['results']['bindings'][i]['codval']['value'].replace('SDN:S25::',''))\n",
    "            b = xstr(r['results']['bindings'][i]['prefLabel']['value'])\n",
    "    list.append([a,b])\n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set input files, local mapping files and results directory for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of input file\n",
    "inputfile = os.path.join(os.getcwd(),os.path.normpath('ICES2P01_test_dset.csv'))\n",
    "\n",
    "# Filepaths for mapping files\n",
    "mapfile = os.path.join(os.getcwd(),'mappings','unmapped_substances.csv')\n",
    "biotamap = os.path.join(os.getcwd(),'mappings','biota_synonym_mapping.csv')\n",
    "p02_file = os.path.join(os.getcwd(),'mappings','ICES2P02_mapping.csv')\n",
    "\n",
    "# Set output file directory\n",
    "results = os.path.join(os.getcwd(),'results')\n",
    "\n",
    "# Set list to capture summary information for reporting at then end of the run\n",
    "summary = []\n",
    "\n",
    "# Set time run started\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "# Add start time and holding space for end time to summary information\n",
    "summary.append([\"Processing started:\" , (start.strftime('%Y-%m-%d %H:%M:%S'))]) \n",
    "summary.append([\"Processing finished:\" , \"\"])\n",
    "summary.append([\"\" , \"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ICES semantic model components for mapping to P01 semantic model from file into a Pandas DataFrame\n",
    "\n",
    "### Example of expected input structure and headings\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"img/input_example.png\"></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_csv(inputfile)\n",
    "inputs.reset_index(inplace=True)\n",
    "inputs = inputs.rename(columns = {'index':'rowID'})\n",
    "\n",
    "# Insert number of rows in the input file in to the summary information\n",
    "print(\"Rows input: %s\" % len(inputs))\n",
    "summary.append([\"Rows input:\", len(inputs)])\n",
    "\n",
    "# Make a working copy of the parameter combinations for mapping\n",
    "param_combo = inputs.copy(deep=True)\n",
    "print(\"Rows for mapping: %s\" % len(param_combo))\n",
    "summary.append([\"Rows for mapping:\", len(param_combo)])\n",
    "\n",
    "# Add columns needed for P01 semantic model\n",
    "# In the working copy set NaNs to '-9' and add columns for mapped NVS semantic model elements\n",
    "param_combo = param_combo.fillna('-9')\n",
    "param_combo = param_combo.assign(S06_label='',              # Measurement Property\n",
    "                                 S07_label='not specified', # Measurement Property Statistic\n",
    "                                 S02_label='',              # Measurement - Matrix relationship\n",
    "                                 )\n",
    "param_combo['PARAM'] = param_combo['PARAM'].str.upper()\n",
    "param_combo['AphiaID'] = param_combo['AphiaID'].astype('int32')\n",
    "# Remove leading or trailing spaces from the text columns\n",
    "columns = param_combo.columns.tolist()\n",
    "columns.remove('AphiaID')\n",
    "columns.remove('rowID')\n",
    "for column in columns:\n",
    "    param_combo[column] = param_combo[column].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display sample of sediment ICES parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[param_combo['DTYPE']=='CS'][['rowID','PRNAM','CAS','DTYPE','PARAM','MUNIT','MATRX','BASIS','METPT','METOA','Species','AphiaID','Note']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display sample of water ICES parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[param_combo['DTYPE']=='CW'][['rowID','PRNAM','CAS','DTYPE','PARAM','MUNIT','MATRX','BASIS','METPT','METOA','Species','AphiaID','Note']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display sample of biota ICES parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[param_combo['DTYPE']=='CF'][['rowID','PRNAM','CAS','DTYPE','PARAM','MUNIT','MATRX','BASIS','METPT','METOA','Species','AphiaID','Note']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display sample of P01 parameter codes and semantic model components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load P01 terms and semantic model vocabularies from the NERC Vocabulary Server\n",
    "\n",
    "### For more details of the P01 Parameter Usage Vocabulary and the underlying semantic model please see the IMDIS 2018 presentation: \n",
    "#### Slides: https://www.bodc.ac.uk/about/outputs/presentations_and_papers/documents/imdis2018gmon_alexk.pdf\n",
    "#### Video: https://www.youtube.com/watch?v=ePFqUSsteQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Get the latest semantic model vocabulary contents from the NVS Sparql endpoint\n",
    "\n",
    "a1 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0A++++PREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A++++%0D%0A++++select+%3F\"\n",
    "a2 = \"+%3F\"\n",
    "a3 = \"%0D%0A++++where+%7B%0D%0A++++%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2F\"\n",
    "a4 = \"%2Fcurrent%2F%3E+skos%3Amember+%3Furl+.%0D%0A++++%3Furl+skos%3AprefLabel+%3F\"\n",
    "a5 = \"+.%0D%0A++++%3Furl+skos%3Anotation+%3Fc+.%0D%0A++++%3Furl+owl%3Adeprecated+%27false%27+.%0D%0A++++BIND%28replace%28str%28%3Fc%29%2C%27SDN%3A\"\n",
    "a6 = \"%3A%3A%27%2C%27%27%2C%27i%27%29+AS+%3F\"\n",
    "a7 = \"%29%0D%0A++++%7D&output=csv&stylesheet=\"\n",
    "\n",
    "S06 = pd.read_csv(a1+'S06'+a2+'S06_label'+a3+'S06'+a4+'S06_label'+a5+'S06'+a6+'S06'+a7)\n",
    "S07 = pd.read_csv(a1+'S07'+a2+'S07_label'+a3+'S07'+a4+'S07_label'+a5+'S07'+a6+'S07'+a7)\n",
    "S02 = pd.read_csv(a1+'S02'+a2+'S02_label'+a3+'S02'+a4+'S02_label'+a5+'S02'+a6+'S02'+a7)\n",
    "S26 = pd.read_csv(a1+'S26'+a2+'S26_label'+a3+'S26'+a4+'S26_label'+a5+'S26'+a6+'S26'+a7)\n",
    "S03 = pd.read_csv(a1+'S03'+a2+'S03_label'+a3+'S03'+a4+'S03_label'+a5+'S03'+a6+'S03'+a7)\n",
    "S04 = pd.read_csv(a1+'S04'+a2+'S04_label'+a3+'S04'+a4+'S04_label'+a5+'S04'+a6+'S04'+a7)\n",
    "S05 = pd.read_csv(a1+'S05'+a2+'S05_label'+a3+'S05'+a4+'S05_label'+a5+'S05'+a6+'S05'+a7)\n",
    "P01 = pd.read_csv(a1+'P01'+a2+'P01_label'+a3+'P01'+a4+'P01_label'+a5+'P01'+a6+'P01'+a7)\n",
    "\n",
    "# Download semantic component mapping\n",
    "\n",
    "urlS06 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS06+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS06%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Anarrower+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS06%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS06%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S06_P01 = pd.read_csv(urlS06)\n",
    "print(\"P01-S06 mapping downloaded.\")\n",
    "\n",
    "urlS07 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS07+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS07%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Anarrower+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS07%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS07%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S07_P01 = pd.read_csv(urlS07)\n",
    "print(\"P01-S07 mapping downloaded.\")\n",
    "\n",
    "urlS27 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS27+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS27%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Anarrower+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS27%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS27%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S27_P01 = pd.read_csv(urlS27)\n",
    "print(\"P01-S27 mapping downloaded.\")\n",
    "\n",
    "urlS02 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS02+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS02%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS02%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS02%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S02_P01 = pd.read_csv(urlS02)\n",
    "print(\"P01-S02 mapping downloaded.\")\n",
    "\n",
    "urlS26 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS26+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS26%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Anarrower+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS26%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS26%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S26_P01 = pd.read_csv(urlS26)\n",
    "print(\"P01-S26 mapping downloaded.\")\n",
    "\n",
    "urlS25 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS25+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Anarrower+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS25%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS25%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S25_P01 = pd.read_csv(urlS25)\n",
    "print(\"P01-S25 mapping downloaded.\")\n",
    "\n",
    "urlS03 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS03+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS03%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS03%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS03%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S03_P01 = pd.read_csv(urlS03)\n",
    "print(\"P01-S03 mapping downloaded.\")\n",
    "\n",
    "urlS04 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS04+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS04%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS04%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS04%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S04_P01 = pd.read_csv(urlS04)\n",
    "print(\"P01-S04 mapping downloaded.\")\n",
    "\n",
    "urlS05 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS05+%3FP01%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS05%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FP01%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AP01%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FP01%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS05%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS05%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S05_P01 = pd.read_csv(urlS05)\n",
    "print(\"P01-S05 mapping downloaded.\")\n",
    "\n",
    "# Build P01 semantic model dataframe\n",
    "P01 = pd.merge(P01, S06_P01, how='left', on='P01')\n",
    "P01 = pd.merge(P01, S07_P01, how='left', on='P01')\n",
    "P01 = pd.merge(P01, S27_P01, how='left', on='P01')\n",
    "P01 = pd.merge(P01, S02_P01, how='left', on='P01')\n",
    "P01 = pd.merge(P01, S26_P01, how='left', on='P01')\n",
    "P01 = pd.merge(P01, S25_P01, how='left', on='P01')\n",
    "P01 = pd.merge(P01, S03_P01, how='left', on='P01')\n",
    "P01 = pd.merge(P01, S04_P01, how='left', on='P01')\n",
    "P01 = pd.merge(P01, S05_P01, how='left', on='P01')\n",
    "\n",
    "P01 = P01.fillna(value={'S25': 'BE007736', 'S07': 'S0700006', 'S03': 'S0316', 'S04': 'S0421', 'S05': 'S050003'})\n",
    "\n",
    "print(\"P01 semantic model dataframe constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(P01[P01['P01_label'].str.contains('copper')].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping of chemical PARAMs and NVS S27 vocabulary entries\n",
    "### Determine where direct mappings already published on the NVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get S27 terms that have a mapping to ICES PARAM vocabulary published from the NVS\n",
    "q = \"\"\"PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "                    \n",
    "    select ?PARAM ?S27 ?S27_label \n",
    "    where {\n",
    "           <http://vocab.nerc.ac.uk/collection/S27/current/> skos:member ?url .\n",
    "           ?url skos:notation ?a .\n",
    "           ?url skos:prefLabel ?S27_label .\n",
    "           ?url owl:deprecated 'false' .\n",
    "           ?url skos:related ?c .\n",
    "           FILTER(regex(str(?c), \"http://vocab.ices.dk/services/rdf/collection/PARAM/\", \"i\")) .\n",
    "           BIND(substr(?a,10,8) as ?S27) .\n",
    "           BIND(replace(str(?c), \"http://vocab.ices.dk/services/rdf/collection/PARAM/\", \"\", \"i\") AS ?PARAM) .\n",
    "          }\"\"\"\n",
    "# URL for the above query is:\n",
    "url = \"\"\"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0A++++PREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A++++++++++++++++++++%0D%0A++++select+%3FPARAM+%3FS27+%3FS27_label+%0D%0A++++where+%7B%0D%0A+++++++++++%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS27%2Fcurrent%2F%3E+skos%3Amember+%3Furl+.%0D%0A+++++++++++%3Furl+skos%3Anotation+%3Fa+.%0D%0A+++++++++++%3Furl+skos%3AprefLabel+%3FS27_label+.%0D%0A+++++++++++%3Furl+owl%3Adeprecated+%27false%27+.%0D%0A+++++++++++%3Furl+skos%3Arelated+%3Fc+.%0D%0A+++++++++++FILTER%28regex%28str%28%3Fc%29%2C+%22http%3A%2F%2Fvocab.ices.dk%2Fservices%2Frdf%2Fcollection%2FPARAM%2F%22%2C+%22i%22%29%29+.%0D%0A+++++++++++BIND%28substr%28%3Fa%2C10%2C8%29+as+%3FS27%29+.%0D%0A+++++++++++BIND%28replace%28str%28%3Fc%29%2C+%22http%3A%2F%2Fvocab.ices.dk%2Fservices%2Frdf%2Fcollection%2FPARAM%2F%22%2C+%22%22%2C+%22i%22%29+AS+%3FPARAM%29+.%0D%0A++++++++++%7D&output=CSV&stylesheet=\"\"\"\n",
    "\n",
    "# More efficient to ingest SPARQL response as a CSV directly into a Pandas DataFrame\n",
    "mapped_chems = pd.read_csv(url)\n",
    "mapped_chems['SOURCE'] = 'NVS'\n",
    "\n",
    "print(\"Number of ICES PARAM terms directly mapped to S27 chemical substance terms from NVS: %s\" % (len(mapped_chems)))\n",
    "summary.append([\"Number of ICES PARAM terms directly mapped to S27 chemical substance terms from NVS:\", (len(mapped_chems))])\n",
    "\n",
    "display(mapped_chems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get local ICES PARAM to NVS S27 substance mapping from mapping file location provided earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_map = pd.read_csv(mapfile)\n",
    "local_map['SOURCE'] = mapfile\n",
    "\n",
    "print(\"Number of local mappings for chemical substances from file: %s\" % (len(local_map)))\n",
    "summary.append([\"Number of local mappings for chemical substances from file:\" , (len(local_map))])\n",
    "\n",
    "display(local_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify any mappings in the local file also published from the NVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_map = pd.merge(mapped_chems, local_map, how='inner', on='PARAM')\n",
    "\n",
    "print(\"Number of chemical substance mappings in both local file and NVS: %s\" % (len(duplicate_map)))\n",
    "summary.append([\"Number of chemical substance mappings in both local file and NVS:\" , (len(duplicate_map))])\n",
    "\n",
    "display(duplicate_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display local mappings, where CAS RN do not match between NVS and ICES or are absent, for review with BODC vocab team (vocab.services@bodc.ac.uk) for upload to NVS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(local_map[local_map['ICES_CASRN']!=local_map['NVS_CASRN']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For unmapped chemical PARAMs with CAS numbers, check if the chemical substance exists within S27 and then map via CAS number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARQL query for all NVS substances with CAS numbers from the SPARQL endpoint\n",
    "q =  \"\"\"PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "            \n",
    "    select ?nvs_codval ?nvs_prefLabel ?nvs_casrn\n",
    "    where {\n",
    "           <http://vocab.nerc.ac.uk/collection/S27/current/> skos:member ?url .\n",
    "           ?url skos:notation ?a .\n",
    "           ?url skos:prefLabel ?nvs_prefLabel .\n",
    "           ?url owl:deprecated 'false' .\n",
    "           ?url owl:sameAs ?c .\n",
    "           FILTER(regex(str(?c), \"https://chem.nlm.nih.gov/chemidplus/rn/\", \"i\")) .\n",
    "           BIND(replace(str(?a),'SDN:S27::','','i') AS ?nvs_codval) .\n",
    "           BIND(replace(str(?c),'https://chem.nlm.nih.gov/chemidplus/rn/','','i') AS ?nvs_casrn) .\n",
    "          }\"\"\"                \n",
    "\n",
    "# URL for the above query is:\n",
    "url = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX%20skos%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0APREFIX%20owl%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0A%0Aselect%20%3Fnvs_codval%20%3Fnvs_prefLabel%20%3Fnvs_casrn%0Awhere%20%7B%0A%20%20%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS27%2Fcurrent%2F%3E%20skos%3Amember%20%3Furl%20.%0A%20%20%3Furl%20skos%3Anotation%20%3Fa%20.%0A%20%20%3Furl%20skos%3AprefLabel%20%3Fnvs_prefLabel%20.%0A%20%20%3Furl%20owl%3Adeprecated%20'false'%20.%0A%20%20%3Furl%20owl%3AsameAs%20%3Fc%20.%0A%20%20FILTER(regex(str(%3Fc)%2C'https%3A%2F%2Fchem.nlm.nih.gov%2Fchemidplus%2Frn%2F'%2C'i'))%20.%0A%20%20BIND(replace(str(%3Fa)%2C'SDN%3AS27%3A%3A'%2C''%2C'i')%20AS%20%3Fnvs_codval)%20.%0A%20%20BIND(replace(str(%3Fc)%2C'https%3A%2F%2Fchem.nlm.nih.gov%2Fchemidplus%2Frn%2F'%2C''%2C'i')%20AS%20%3Fnvs_casrn)%20.%0A%7D&output=csv&stylesheet=\"   \n",
    "\n",
    "# More efficient to ingest SPARQL response as a CSV directly into a Pandas DataFrame\n",
    "nvs_cas = pd.read_csv(url)\n",
    "\n",
    "print(\"Number of chemical substances in S27 with a CAS number: %s\" % len(nvs_cas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine NVS mappings and local file then apply mapping to input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas_map = nvs_cas.drop_duplicates(subset=['nvs_casrn'], keep=False).rename(columns={\"nvs_codval\": \"S27\", \"nvs_prefLabel\": \"S27_label\", \"nvs_casrn\": \"CAS\"})\n",
    "cas_map['SOURCE']='CASRN'\n",
    "\n",
    "# Remove duplicate records for as CASRN from the NVS and concatenate all remaining mappings giving precidence to the local mappings where there is duplication\n",
    "full_chem_map = pd.concat([mapped_chems,\n",
    "                           local_map[['PARAM','S27','S27_label','SOURCE']], \n",
    "                           pd.merge(param_combo[(param_combo['CAS']!=-9)][['PARAM','CAS']],cas_map,how='inner', on='CAS').drop_duplicates()],\n",
    "                          sort=True                          \n",
    "                         ).drop_duplicates(subset='PARAM', keep='first').reset_index(drop=True)\n",
    "\n",
    "# Add S27 semantic model mapping to the main table based on the combinations provided   \n",
    "param_combo = pd.merge(param_combo, full_chem_map.drop(columns=['CAS']), how='left', on=['PARAM'])\n",
    "\n",
    "print(\"Rows mapped from NVS and local mapping of chemical substance: %s\" % len(param_combo[param_combo['S27'].notnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display mapping progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[['rowID','PRNAM','CAS','DTYPE','PARAM','MUNIT','MATRX','BASIS','METPT','METOA','Species','AphiaID','Note','S06_label','S07_label','S27_label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the contents of the input file determine if any new local PARAM to S27 mappings are required for chemical PARAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[(param_combo['S27'].isnull()) & (param_combo['CAS']!='-9')][['PRNAM','CAS','PARAM','S27','S27_label','SOURCE']].drop_duplicates().sort_values('CAS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check no chemical codes present among those rows without a CAS entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[(param_combo['S27'].isnull()) & (param_combo['CAS']=='-9')][['PRNAM','CAS','PARAM','S27','S27_label','SOURCE']].drop_duplicates().sort_values('CAS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where mappings don't exist for chemical PARAMs or can't be made via CAS number as listed above:\n",
    "#### Either:\n",
    "#### - Add mapping to local file and re-run previous steps\n",
    "#### - Continue process and these rows will not be able to be mapped to a P01 term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark rows that require chemical substance mapping with S27 as \"manual mapping required\"\n",
    "param_combo.loc[(param_combo['S27'].isnull()) & (param_combo['CAS']!='-9'),'S27_label'] = 'manual mapping required'\n",
    "# Mark rows that do not require chemical substance mapping with S27 as \"not applicable\"    \n",
    "param_combo.loc[(param_combo['S27'].isnull()) & (param_combo['CAS']=='-9'),'S27_label'] = 'not applicable'\n",
    "\n",
    "# Generate list of new substances to be added to S27\n",
    "S27_cols = ['PARGROUP','PARAM','PRNAM','CAS','S27_label','S27']\n",
    "S27new = param_combo[param_combo['S27_label']=='manual mapping required'][S27_cols].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "S27new_file = os.path.join(results,'new_S27.csv')\n",
    "S27new.to_csv(S27new_file, index=False)\n",
    "print(\"Subset of new S27 terms for creation or manual mapping saved to: %s\" % S27new_file)\n",
    "\n",
    "# Generate list of PARAMs to be mapped to another element of the semantic model\n",
    "altmap_cols = ['PARGROUP','PARAM','PRNAM','CAS']\n",
    "alt_mapping = param_combo[param_combo['S27_label']=='not applicable'][altmap_cols].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "altmap_file = os.path.join(results,'alt_mappings.csv')\n",
    "alt_mapping.to_csv(altmap_file, index=False)\n",
    "print(\"Subset of PARAMs for creation or manual mapping to another part of the semantic model saved to: %s\" % altmap_file)\n",
    "\n",
    "print(\"Total combinations = %s\" % (len(param_combo)))\n",
    "\n",
    "PARAMs2map = pd.DataFrame()\n",
    "PARAMs2map = param_combo[['PARAM','PRNAM']][param_combo['S27_label']=='not applicable'].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping of ICS DTYPE, MATRX and METPT combinations to P01 semantic component S26\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"img/matrix_mapping.png\"></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_check = param_combo[['DTYPE','MATRX','METPT']].drop_duplicates().copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "# Set to default of 'Check MATRX. Not mapped.'\n",
    "matrix_check = matrix_check.assign(S26_label = 'Check DTYPE/MATRX/METPT combination. Not mapped.')\n",
    "\n",
    "print(\"Number of MATRX for P01 mapping: %s\" % len(matrix_check))\n",
    "summary.append([\"Number of MATRX for P01 mapping:\" , len(matrix_check)])\n",
    "\n",
    "for index, row in matrix_check.iterrows():\n",
    "    if row['DTYPE'] == 'CF':\n",
    "        # Set S26 label to 'biota'\n",
    "        row['S26_label'] = 'biota'\n",
    "\n",
    "    elif row['DTYPE'] == 'CS':\n",
    "        if row['MATRX'] == 'SEDTOT':\n",
    "            row['S26_label'] = 'sediment'\n",
    "        elif row['MATRX'][3:len(row['MATRX'])] != 'TOT':\n",
    "            row['S26_label'] = 'sediment <'+row['MATRX'][3:len(row['MATRX'])] +'um'\n",
    "            \n",
    "    elif row['DTYPE'] == 'CW':\n",
    "        if row['MATRX'] == 'WT':\n",
    "            if row['METPT'] == '-9':\n",
    "                row['S26_label'] = 'water body [dissolved plus reactive particulate <unknown phase]'\n",
    "            else:\n",
    "                metpt_list = row['METPT'].split('~')               \n",
    "                for metpt in metpt_list:\n",
    "                    if metpt in ('NF','NONE','NA','CP'):\n",
    "                        row['S26_label'] = 'water body [dissolved plus reactive particulate phase]'\n",
    "                        continue\n",
    "                    elif metpt in('GFF','GF/F','FF-GF-0.7'):\n",
    "                        row['S26_label'] = 'water body [dissolved plus reactive particulate <GF/F phase]'\n",
    "                        continue\n",
    "                    elif metpt in('GFC','GF/C','FF-GF-1.2','FF-PP-1.2'):\n",
    "                        row['S26_label'] = 'water body [dissolved plus reactive particulate <GF/C phase]'\n",
    "                        continue\n",
    "                    elif metpt in('FM-PC-0.4','FM-PC-0.45','FM-PES-0.45','FM-CN-0.45','FM-CA-0.45','PCF40','PCF45','PCF'):\n",
    "                        row['S26_label'] = 'water body [dissolved plus reactive particulate <0.4/0.45um phase]'\n",
    "                        continue\n",
    "                    elif metpt in('F'):\n",
    "                        row['S26_label'] = 'water body [dissolved plus reactive particulate <unknown phase]'\n",
    "                        continue\n",
    "                    elif metpt in('FM-CA-0.2'):\n",
    "                        row['S26_label'] = 'water body [dissolved plus reactive particulate <0.2um phase]'\n",
    "                        continue\n",
    "\n",
    "    #print(\"Row %s of %s matrix combinations mapped.\" % (index+1,len(matrix_check))) # Commented out used in debugging\n",
    "#display(matrix_check)    \n",
    "\n",
    "# Subset potential S26 new entries\n",
    "S26new = matrix_check[matrix_check['S26_label']=='Check DTYPE/MATRX/METPT combination. Not mapped.']\n",
    "\n",
    "print(\"Number of potential new S26 terms: %s\" % len(S26new))\n",
    "summary.append([\"Number of potential new S26 terms:\" , len(S26new)])\n",
    "display(S26new)\n",
    "\n",
    "# Retain those combinations that have not yet been mapped to P01\n",
    "S26new_file = os.path.join(results,'new_S26.csv')\n",
    "S26new.to_csv(S26new_file, index=False)\n",
    "print(\"Subset of new S26 terms for creation saved to: %s\" % S26new_file)\n",
    "\n",
    "# Add S26 semantic model mapping to the main table based on the combinations provided   \n",
    "param_combo = pd.merge(param_combo, matrix_check, how='left', on=['DTYPE','MATRX','METPT'])\n",
    "\n",
    "print(\"Total combinations = %s\" % (len(param_combo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display mapping progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[['PRNAM','CAS','DTYPE','PARAM','MUNIT','MATRX','BASIS','METPT','METOA','Species','AphiaID','Note','S06_label','S07_label','S27_label','S26_label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxon, WoRMS AphiaID, ITIS TSN combination check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all existing TAXONs from S25 and simplify text labels to show distinct TAXON values from the S25 semantic model\n",
    "url = \"\"\"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0A++++PREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A++++++++++++++++++++%0D%0A++++select+distinct+%3FAphiaID+%3FTAXON%0D%0A++++where+%7B%0D%0A+++++++++++%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furl+.%0D%0A+++++++++++%3Furl+skos%3AprefLabel+%3FprefLabel+.%0D%0A+++++++++++%3Furl+owl%3Adeprecated+%27false%27+.%0D%0A+++++++++++FILTER%28regex%28str%28%3FprefLabel%29%2C+%22WoRMS%22%2C+%22i%22%29%29+.%0D%0A+++++++++++BIND%28replace%28str%28%3FprefLabel%29%2C+%22%5C%5C+%5C%5C%5B.*%3F%5C%5C%5D%22%2C%22%22%2C+%22i%22%29+AS+%3FTAXON%29+.%0D%0A+++++++++++BIND%28replace%28replace%28replace%28str%28%3FTAXON%29%2C+%22%5C%5C%29%22%2C%22%22%2C+%22i%22%29%2C+%22.*%28%3F%3DWoRMS+%29%22%2C+%22%22%2C+%22i%22%29%2C+%22WoRMS+%22%2C+%22%22%2C+%22i%22%29+AS+%3FAphiaID%29+.%0D%0A++++++++++%7D%0D%0A++++order+by+%3FAphiaID%0D%0A&output=CSV&stylesheet=CSV\"\"\"\n",
    "\n",
    "S25taxon = pd.read_csv(url)\n",
    "\n",
    "# Identify multiple TAXONs per AphiaID within S25\n",
    "S25taxon_duplicates = S25taxon[S25taxon.duplicated(['AphiaID'], keep=False)].copy(deep=True)\n",
    "S25taxon_duplicates.replace(u'\\xc2\\xa0',u' ', regex=True, inplace=True)\n",
    "S25taxon_duplicates.replace(u'\\u2019',u\"'\", regex=True, inplace=True)\n",
    "\n",
    "# Remove duplicate TAXON records from S25taxon dataframe\n",
    "S25taxon_clean = pd.concat([S25taxon, S25taxon_duplicates]).drop_duplicates(keep=False).copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "# Create a Pandas DataFrame and populate with unique combinations of Species and AphiaID from the input file\n",
    "input_taxa_check = pd.DataFrame()\n",
    "input_taxa_check = param_combo[['Species','AphiaID']][param_combo['Species']!='-9'].drop_duplicates().reset_index(drop=True)\n",
    "input_taxa_check = input_taxa_check.astype({\"AphiaID\": int})\n",
    "\n",
    "print(\"Number of Species for P01 mapping: %s\" % len(input_taxa_check))\n",
    "summary.append([\"Number of Species for P01 mapping:\" , len(input_taxa_check)])\n",
    "#%%\n",
    "# Function to call WoRMS web service\n",
    "def worms_check(url):\n",
    "    request = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    if response.code==204:\n",
    "        e = 'No AphiaID found.'\n",
    "    elif response.code==206:\n",
    "        e = 'Multiple AphiaID found.'\n",
    "    elif response.code==200:\n",
    "        e = response.read()\n",
    "    return e\n",
    "\n",
    "# If AphiaID is absent then lookup using the WoRMS web service\n",
    "for index, row in input_taxa_check.iterrows():\n",
    "    if row['AphiaID'] == -9:\n",
    "        if '&' not in row['Species']:\n",
    "            url = 'http://marinespecies.org/rest/AphiaIDByName/%s?marine_only=true' % row['Species'].replace(\" \",\"%20\")\n",
    "            input_taxa_check.loc[index, 'AphiaID'] = worms_check(url)\n",
    "        else:\n",
    "            input_taxa_check.loc[index, 'AphiaID'] = 'Combination of taxa'\n",
    "\n",
    "inputs_aphia = pd.merge(inputs, input_taxa_check, on='Species')\n",
    "\n",
    "\n",
    "#%% \n",
    "# Get WoRMS scientific names from AphiaID provided using WoRMS web service\n",
    "def worms_check(url):\n",
    "    request = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    if response.code==204:\n",
    "        list.append('No response.')\n",
    "    elif response.code==200:\n",
    "        e = response.read()\n",
    "    return json.loads(e)\n",
    "       \n",
    "worms = pd.DataFrame()        \n",
    "\n",
    "aphia_list = input_taxa_check['AphiaID'].tolist()\n",
    "y = len(aphia_list)\n",
    "if y<50:\n",
    "    ids = ''\n",
    "    for i in range(0,50):\n",
    "        ids = ids + 'aphiaids%5B%5D=' + str(aphia_list[i]) + '&'\n",
    "    url = 'http://www.marinespecies.org/rest/AphiaRecordsByAphiaIDs?%s' % ids[0:-1]\n",
    "    worms = pd.DataFrame(worms_check(url), ignore_index=True)\n",
    "elif y>50:\n",
    "    for j in range(0,int(y/50)):\n",
    "        ids = ''\n",
    "        for i in range(j*50,min((j+1)*50,y)):\n",
    "            ids = ids + 'aphiaids%5B%5D=' + str(aphia_list[i]) + '&'\n",
    "        url = 'http://www.marinespecies.org/rest/AphiaRecordsByAphiaIDs?%s' % ids[0:-1]\n",
    "        worms = pd.concat([worms, pd.DataFrame(worms_check(url))], ignore_index=True)\n",
    "    ids = ''\n",
    "    for i in range((j+1)*50,min((j+2)*50,y)):\n",
    "        ids = ids + 'aphiaids%5B%5D=' + str(aphia_list[i]) + '&'\n",
    "    url = 'http://www.marinespecies.org/rest/AphiaRecordsByAphiaIDs?%s' % ids[0:-1]\n",
    "    worms = pd.concat([worms, pd.DataFrame(worms_check(url))], ignore_index=True)\n",
    "\n",
    "input_taxa_check = pd.merge(input_taxa_check, worms[['AphiaID','scientificname']], how='left', on='AphiaID')\n",
    "\n",
    "input_taxa_check = input_taxa_check.rename(index=str, columns={'scientificname': 'name_from_AphiaID'})\n",
    "\n",
    "# Set column to indicate if a discrepancy to be resolved exists based on Scientific names not matching\n",
    "a = input_taxa_check.Species == input_taxa_check.name_from_AphiaID\n",
    "input_taxa_check['proceed'] = np.where(a, 'Yes', 'No')\n",
    "\n",
    "# Subset those taxa where naming discrepancy exists\n",
    "taxa_discrepancy = input_taxa_check[input_taxa_check['proceed']=='No'].reset_index(drop=True)\n",
    "\n",
    "print(\"Number of Species with name discrepancy between taxon-AphiaID combination in file and WoRMS: %s\" % len(taxa_discrepancy))\n",
    "summary.append([\"Number of Species with name discrepancy between taxon-AphiaID combination in file and WoRMS:\" , len(taxa_discrepancy)])\n",
    "display(taxa_discrepancy)\n",
    "\n",
    "# Save taxa discrepancies\n",
    "taxadis_file = os.path.join(results,'taxa_discrepancy.csv')\n",
    "taxa_discrepancy.to_csv(taxadis_file, index=False)\n",
    "print(\"Taxa discrepancies saved to: %s\" % taxadis_file)\n",
    "\n",
    "# Map AphiaID to S25 component TAXON for the non-duplicate AphiaID results in S25\n",
    "taxa_map = pd.merge(input_taxa_check[['AphiaID','name_from_AphiaID']],\n",
    "                    S25taxon_clean, \n",
    "                    how='left', \n",
    "                    on='AphiaID')\n",
    "taxa_map = taxa_map.fillna(value={'TAXON': 'New TAXON required.'}).drop_duplicates()\n",
    "\n",
    "\n",
    "# Add TAXON mapping to the main table based on the AphiaID provided    \n",
    "param_combo = pd.merge(param_combo, taxa_map, how='left', on='AphiaID')\n",
    "\n",
    "# Mark rows that do not require mapping as \"Not applicable.\"    \n",
    "param_combo = param_combo.fillna(value={'TAXON': 'not specified', 'name_from_AphiaID': '-9'})\n",
    "\n",
    "print(\"Total combinations = %s\" % (len(param_combo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display mapping progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[(param_combo['DTYPE']=='CF')][['PRNAM','CAS','DTYPE','PARAM','MUNIT','MATRX','BASIS','METPT','METOA','Species','AphiaID','Note','S06_label','S07_label','S27_label','S26_label','TAXON']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New entries required in S25 semantic model TAXON vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(taxa_map[taxa_map['TAXON']=='New TAXON required.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map remaining terms of the P01 semantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combo['S02_label'] = pd.Series(dtype='object')\n",
    "\n",
    "param_combo.loc[(param_combo['BASIS']=='L'),'S06_label'] = 'Lipid-normalised concentration'\n",
    "param_combo.loc[(param_combo['MUNIT']=='%'),'S06_label'] = 'Proportion'\n",
    "param_combo.loc[(param_combo['MUNIT'].str.contains('Bq')),'S06_label'] = 'Activity'\n",
    "param_combo.loc[(param_combo['MUNIT']=='ntu') & (param_combo['PARAM']=='TURB'),'S06_label'] = 'Turbidity'\n",
    "param_combo.loc[(param_combo['MUNIT'].str.contains('Bq')==False) & (param_combo['MUNIT'].str[-1].isin(['l','g'])),'S06_label'] = 'Concentration'\n",
    "\n",
    "param_combo.loc[(param_combo['MUNIT'].str[-1] == 'l'),'S02_label'] = 'per unit volume of the'\n",
    "param_combo.loc[(param_combo['MUNIT'].str[-1] == 'g'),'S02_label'] = 'per unit mass of the'\n",
    "param_combo.loc[(param_combo['BASIS']=='D'),'S02_label'] = 'per unit dry weight of'\n",
    "param_combo.loc[(param_combo['BASIS']=='W'),'S02_label'] = 'per unit wet weight of'\n",
    "param_combo.loc[(param_combo['BASIS']=='L'),'S02_label'] = 'in'\n",
    "param_combo.loc[(param_combo['MUNIT']=='ntu') & (param_combo['PARAM']=='TURB'),'S02_label'] = 'of the'\n",
    "\n",
    "param_combo.loc[(param_combo['MUNIT']=='-9') & (param_combo['CAS']!='-9') & (param_combo['DTYPE']=='CF') & (param_combo['S06_label']==''),'S06_label'] = 'Concentration'\n",
    "\n",
    "param_combo['S03_label'] = 'not specified'\n",
    "param_combo['S04_label'] = 'not specified'\n",
    "param_combo['S05_label'] = 'not specified'\n",
    "\n",
    "print(\"Number of rows in DataFrame: %s\" % len(param_combo))\n",
    "\n",
    "display(param_combo[(param_combo['DTYPE']=='CF')][['PRNAM','CAS','DTYPE','PARAM','MUNIT','MATRX','BASIS','METPT','METOA','Species','AphiaID','Note','S06_label','S07_label','S27_label','S02_label','S26_label','TAXON']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map matrix of the biota to appropriate NVS S25 SUBCOMPONENT and/or STAGE. Note some constraints based on taxa type applied in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combo['SIZE'] = pd.Series(dtype='object')\n",
    "param_combo['SEX'] = pd.Series(dtype='object')\n",
    "param_combo['STAGE'] = pd.Series(dtype='object')\n",
    "param_combo['SUBCOMPONENT'] = pd.Series(dtype='object')\n",
    "param_combo['SUBGROUP'] = pd.Series(dtype='object')\n",
    "param_combo['MORPHOLOGY'] = pd.Series(dtype='object')\n",
    "param_combo['COLOUR'] = pd.Series(dtype='object')\n",
    "\n",
    "# Direct 1-2-1 mappings\n",
    "param_combo.loc[param_combo['MATRX'] == 'WO','SUBCOMPONENT'] = 'not specified'\n",
    "param_combo.loc[param_combo['MATRX'] == 'TM','SUBCOMPONENT'] = 'muscle tissue'\n",
    "param_combo.loc[param_combo['MATRX'] == 'SI','SUBCOMPONENT'] = 'not specified'\n",
    "param_combo.loc[param_combo['MATRX'] == 'SH','SUBCOMPONENT'] = 'shell'\n",
    "param_combo.loc[param_combo['MATRX'] == 'MU&EP','SUBCOMPONENT'] = 'muscle tissues and skin'\n",
    "param_combo.loc[param_combo['MATRX'] == 'LI','SUBCOMPONENT'] = 'liver'\n",
    "param_combo.loc[param_combo['MATRX'] == 'KI','SUBCOMPONENT'] = 'kidney'\n",
    "param_combo.loc[param_combo['MATRX'] == 'GO','SUBCOMPONENT'] = 'gonads'\n",
    "param_combo.loc[param_combo['MATRX'] == 'GI','SUBCOMPONENT'] = 'gill'\n",
    "param_combo.loc[param_combo['MATRX'] == 'FE','SUBCOMPONENT'] = 'feathers'\n",
    "param_combo.loc[param_combo['MATRX'] == 'FA','SUBCOMPONENT'] = 'body fat'                                             \n",
    "param_combo.loc[param_combo['MATRX'] == 'EP','SUBCOMPONENT'] = 'skin'\n",
    "param_combo.loc[param_combo['MATRX'] == 'BS','SUBCOMPONENT'] = 'blood serum'\n",
    "param_combo.loc[param_combo['MATRX'] == 'BR','SUBCOMPONENT'] = 'brain'\n",
    "param_combo.loc[param_combo['MATRX'] == 'BL','SUBCOMPONENT'] = 'blood'\n",
    "param_combo.loc[param_combo['MATRX'] == 'BC','SUBCOMPONENT'] = 'blood cells'\n",
    "                                                 \n",
    "param_combo.loc[param_combo['MATRX'].isin(['EG','EH','RO']),'STAGE'] = 'eggs'\n",
    "                                                 \n",
    "param_combo.loc[param_combo['MATRX'] == 'EH','SUBCOMPONENT'] = 'egg yolk and albumen homogenate'\n",
    "\n",
    "param_combo.loc[(param_combo['MATRX'] == 'MU') & (param_combo['Species'] == 'Loligo vulgaris'),'SUBCOMPONENT'] = 'flesh'\n",
    "param_combo.loc[(param_combo['MATRX'] == 'MU') & (param_combo['Species'] != 'Loligo vulgaris'),'SUBCOMPONENT'] = 'muscle tissue'\n",
    "param_combo.loc[(param_combo['MATRX'] == 'EX') & (param_combo['Species'] == 'Mytilus edulis'),'SUBCOMPONENT'] = 'shell'\n",
    "param_combo.loc[(param_combo['MATRX'] == 'EX') & (param_combo['Species'] != 'Mytilus edulis'),'SUBCOMPONENT'] ='Checking species-matrx combo validity with ICES.'\n",
    "param_combo.loc[(param_combo['MATRX'] == 'BB') & (param_combo['Note'] != 'Fish'),'SUBCOMPONENT'] = 'blubber'\n",
    "param_combo.loc[(param_combo['MATRX'] == 'BB') & (param_combo['Note'] == 'Fish'),'SUBCOMPONENT'] = 'Checking species-matrx combo validity with ICES.'\n",
    "\n",
    "param_combo.loc[(param_combo['MATRX'] == 'SB') & (param_combo['Species'].isin(['Gobius','Crangon crangon','Mysidacea'])==False),'SUBCOMPONENT'] = 'flesh'\n",
    "param_combo.loc[(param_combo['MATRX'] == 'SB') & (param_combo['Species'].isin(['Gobius','Crangon crangon','Mysidacea'])),'SUBCOMPONENT'] = 'Checking species-matrx combo validity with ICES.'\n",
    "\n",
    "# Mark empty SUBCOMPONENT and STAGE cells as 'not specified'\n",
    "param_combo = param_combo.fillna(value={'SUBCOMPONENT': 'not specified', \n",
    "                                        'STAGE': 'not specified',\n",
    "                                        'COLOUR': 'not specified',\n",
    "                                        'SUBGROUP': 'not specified',\n",
    "                                        'SIZE': 'not specified',\n",
    "                                        'SEX': 'not specified',\n",
    "                                        'MORPHOLOGY': 'not specified',\n",
    "                                       }\n",
    "                                )\n",
    "\n",
    "print(\"Number of rows in DataFrame: %s\" % len(param_combo))\n",
    "\n",
    "display(param_combo[(param_combo['DTYPE']=='CF')][['DTYPE','MATRX','Species','AphiaID','Note','TAXON','SUBCOMPONENT','STAGE','COLOUR','SUBGROUP','SIZE','MORPHOLOGY','SEX']].drop_duplicates().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Biological Entity (S25) semantic model from the NVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Get the latest semantic model vocabulary contents from the NVS Sparql endpoint\n",
    "\n",
    "a1 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0A++++PREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A++++%0D%0A++++select+%3F\"\n",
    "a2 = \"+%3F\"\n",
    "a3 = \"%0D%0A++++where+%7B%0D%0A++++%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2F\"\n",
    "a4 = \"%2Fcurrent%2F%3E+skos%3Amember+%3Furl+.%0D%0A++++%3Furl+skos%3AprefLabel+%3F\"\n",
    "a5 = \"+.%0D%0A++++%3Furl+skos%3Anotation+%3Fc+.%0D%0A++++%3Furl+owl%3Adeprecated+%27false%27+.%0D%0A++++BIND%28replace%28str%28%3Fc%29%2C%27SDN%3A\"\n",
    "a6 = \"%3A%3A%27%2C%27%27%2C%27i%27%29+AS+%3F\"\n",
    "a7 = \"%29%0D%0A++++%7D&output=csv&stylesheet=\"\n",
    "\n",
    "S09 = pd.read_csv(a1+'S09'+a2+'S09_label'+a3+'S09'+a4+'S09_label'+a5+'S09'+a6+'S09'+a7)\n",
    "S10 = pd.read_csv(a1+'S10'+a2+'S10_label'+a3+'S10'+a4+'S10_label'+a5+'S10'+a6+'S10'+a7)\n",
    "S11 = pd.read_csv(a1+'S11'+a2+'S11_label'+a3+'S11'+a4+'S11_label'+a5+'S11'+a6+'S11'+a7)\n",
    "S12 = pd.read_csv(a1+'S12'+a2+'S12_label'+a3+'S12'+a4+'S12_label'+a5+'S12'+a6+'S12'+a7)\n",
    "S13 = pd.read_csv(a1+'S13'+a2+'S13_label'+a3+'S13'+a4+'S13_label'+a5+'S13'+a6+'S13'+a7)\n",
    "S14 = pd.read_csv(a1+'S14'+a2+'S14_label'+a3+'S14'+a4+'S14_label'+a5+'S14'+a6+'S14'+a7)\n",
    "S15 = pd.read_csv(a1+'S15'+a2+'S15_label'+a3+'S15'+a4+'S15_label'+a5+'S15'+a6+'S15'+a7)\n",
    "S25 = pd.read_csv(a1+'S25'+a2+'S25_label'+a3+'S25'+a4+'S25_label'+a5+'S25'+a6+'S25'+a7)\n",
    "\n",
    "# Download semantic component mapping\n",
    "\n",
    "urlS09 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS09+%3FS25%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS09%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AS25%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS25%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS09%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS09%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S09_S25 = pd.read_csv(urlS09)\n",
    "print(\"S09_S25 mapping downloaded.\")\n",
    "\n",
    "urlS10 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS10+%3FS25%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS10%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AS25%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS25%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS10%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS10%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S10_S25 = pd.read_csv(urlS10)\n",
    "print(\"S10_S25 mapping downloaded.\")\n",
    "\n",
    "urlS11 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS11+%3FS25%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS11%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Anarrower+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AS25%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS25%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS11%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS11%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S11_S25 = pd.read_csv(urlS11)\n",
    "print(\"S11_S25 mapping downloaded.\")\n",
    "\n",
    "urlS12 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS12+%3FS25%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS12%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AS25%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS25%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS12%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS12%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S12_S25 = pd.read_csv(urlS12)\n",
    "print(\"S12_S25 mapping downloaded.\")\n",
    "\n",
    "urlS13 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS13+%3FS25%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS13%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AS25%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS25%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS13%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS13%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S13_S25 = pd.read_csv(urlS13)\n",
    "print(\"S13_S25 mapping downloaded.\")\n",
    "\n",
    "urlS14 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS14+%3FS25%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS14%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AS25%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS25%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS14%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS14%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S14_S25 = pd.read_csv(urlS14)\n",
    "print(\"S14_S25 mapping downloaded.\")\n",
    "\n",
    "urlS15 = \"http://vocab.nerc.ac.uk/sparql/sparql?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+owl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0D%0A%0D%0Aselect+distinct+%3FS15+%3FS25%0D%0Awhere+%7B%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS15%2Fcurrent%2F%3E+skos%3Amember+%3Furla+.%0D%0A%3Furla+owl%3Adeprecated+%27false%27+.%0D%0A%3Furla+skos%3Anotation+%3Fn2+.%0D%0A%3Furla+skos%3Arelated+%3Furlb+.%0D%0A%3Chttp%3A%2F%2Fvocab.nerc.ac.uk%2Fcollection%2FS25%2Fcurrent%2F%3E+skos%3Amember+%3Furlb+.%0D%0A%3Furlb+owl%3Adeprecated+%27false%27+.%0D%0A%3Furlb+skos%3Anotation+%3Fn1+.%0D%0ABIND%28replace%28%3Fn1%2C+%22SDN%3AS25%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS25%29+.%0D%0ABIND%28replace%28%3Fn2%2C+%22SDN%3AS15%3A%3A%22%2C+%22%22%2C+%22i%22%29+AS+%3FS15%29+.%0D%0A%7D&output=csv&stylesheet=\"\n",
    "S15_S25 = pd.read_csv(urlS15)\n",
    "print(\"S15_S25 mapping downloaded.\")\n",
    "\n",
    "# Build S25 semantic model dataframe\n",
    "S25 = pd.merge(S25, S09_S25, how='left', on='S25')\n",
    "S25 = pd.merge(S25, S10_S25, how='left', on='S25')\n",
    "S25 = pd.merge(S25, S11_S25, how='left', on='S25')\n",
    "S25 = pd.merge(S25, S12_S25, how='left', on='S25')\n",
    "S25 = pd.merge(S25, S13_S25, how='left', on='S25')\n",
    "S25 = pd.merge(S25, S14_S25, how='left', on='S25')\n",
    "S25 = pd.merge(S25, S15_S25, how='left', on='S25')\n",
    "\n",
    "S25 = S25.fillna(value={'S09': 'S09133',\n",
    "                        'S10': 'S104',\n",
    "                        'S11': 'S1131',\n",
    "                        'S12': 'S1219',\n",
    "                        'S13': 'S1319',\n",
    "                        'S14': 'S1430',\n",
    "                        'S15': 'S152',\n",
    "                       }\n",
    "                )\n",
    "\n",
    "S25['TAXON'] = S25['S25_label'].str.replace(r\" \\[.*\\]\",\"\", regex=True)\n",
    "\n",
    "print(\"S25 semantic model dataframe constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map biological entity labels to vocabulary codes\n",
    "param_combo = pd.merge(param_combo, S09, how='left', left_on='SIZE', right_on='S09_label').drop(columns=['SIZE'])\n",
    "param_combo = pd.merge(param_combo, S10, how='left', left_on='SEX', right_on='S10_label').drop(columns=['SEX'])\n",
    "param_combo = pd.merge(param_combo, S11, how='left', left_on='STAGE', right_on='S11_label').drop(columns=['STAGE'])\n",
    "param_combo = pd.merge(param_combo, S12, how='left', left_on='SUBCOMPONENT', right_on='S12_label').drop(columns=['SUBCOMPONENT'])\n",
    "param_combo = pd.merge(param_combo, S13, how='left', left_on='SUBGROUP', right_on='S13_label').drop(columns=['SUBGROUP'])\n",
    "param_combo = pd.merge(param_combo, S14, how='left', left_on='MORPHOLOGY', right_on='S14_label').drop(columns=['MORPHOLOGY'])\n",
    "param_combo = pd.merge(param_combo, S15, how='left', left_on='COLOUR', right_on='S15_label').drop(columns=['COLOUR'])\n",
    "\n",
    "# Map Biological entity semantic model combinations to table combinations\n",
    "\n",
    "param_combo = pd.merge(param_combo, S25, how='left', on=['TAXON','S09','S10','S11','S12','S13','S14','S15'])\n",
    "\n",
    "# Reset water and sediment defaults for biological entity\n",
    "param_combo.loc[param_combo['DTYPE'].isin(['CW','CS']),'S25'] = 'BE007736'\n",
    "param_combo.loc[param_combo['DTYPE'].isin(['CW','CS']),'S25_label'] = 'not applicable'\n",
    "\n",
    "S25new = param_combo[(param_combo['DTYPE']=='CF') & (param_combo['S25'].isnull())][['Species','AphiaID','MATRX','S25','S25_label','TAXON','S09_label','S10_label','S11_label','S12_label','S13_label','S14_label','S15_label','S09','S10','S11','S12','S13','S14','S15']].drop_duplicates().sort_values(['Species','MATRX'])\n",
    "\n",
    "# Save new biological entity combinations\n",
    "S25new_file = os.path.join(results,'new_S25.csv')\n",
    "S25new.to_csv(S25new_file, index=False)\n",
    "print(\"New biological entity combinations saved to: %s\" % taxadis_file)\n",
    "print(\"New biological entity combinations: %s\" % len(S25new))\n",
    "\n",
    "print(\"\\nNumber of rows in DataFrame: %s\" % len(param_combo))\n",
    "if len(inputs)<len(param_combo):\n",
    "    print(\"\\nPotential duplicate rows introduced into the DataFrame. Please check output below:\")\n",
    "    display(param_combo[(param_combo['rowID'].duplicated(keep=False))][['rowID','PARAM','MATRX','Species','AphiaID','S25','S25_label','S09_label','S10_label','S11_label','S12_label','S13_label','S14_label','S15_label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display new biological entity combinations for S25 creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(param_combo[(param_combo['DTYPE']=='CF') & (param_combo['S25'].isnull())][['Species','Note','AphiaID','MATRX','S25','S25_label','TAXON','S11_label','S12_label']].drop_duplicates().sort_values(['Species','MATRX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map P01 semantic component labels to vocabulary codes\n",
    "param_combo = pd.merge(param_combo, S06, how='left', on='S06_label')\n",
    "param_combo = pd.merge(param_combo, S07, how='left', on='S07_label')\n",
    "param_combo = pd.merge(param_combo, S02, how='left', on='S02_label')\n",
    "param_combo = pd.merge(param_combo, S26, how='left', on='S26_label')\n",
    "param_combo = pd.merge(param_combo, S03, how='left', on='S03_label')\n",
    "param_combo = pd.merge(param_combo, S04, how='left', on='S04_label')\n",
    "param_combo = pd.merge(param_combo, S05, how='left', on='S05_label')\n",
    "\n",
    "# Map P01 semantic model combinations to table combinations\n",
    "\n",
    "param_combo = pd.merge(param_combo, P01, how='left', on=['S06','S07','S27','S02','S26','S25','S03','S04','S05'])\n",
    "\n",
    "\n",
    "# Replaces any problematic text characters from the NVS imported into the DataFrame\n",
    "# that will cause issues when writing the output to file.\n",
    "param_combo.replace(u'\\xa0',u' ', regex=True, inplace=True)\n",
    "param_combo.replace(u'\\u2019',u\"'\", regex=True, inplace=True)\n",
    "\n",
    "# Reorder columns for output\n",
    "param_combo = param_combo[['rowID','PARGROUP','PRNAM','CAS','DTYPE','PARAM','MUNIT','MATRX','BASIS','METPT','METOA','Note','AphiaID','Species',\n",
    "                          'P01_Code','P01','P01_label','S06_label','S07_label','S27_label','S02_label','S26_label','S25_label',\n",
    "                          'TAXON','S09_label','S10_label','S11_label','S12_label','S13_label','S14_label','S15_label',\n",
    "                          'S06','S07','S27','S02','S26','S25','S09','S10','S11','S12','S13','S14','S15']]\n",
    "\n",
    "print(\"Total combinations in file = %s\" % (len(param_combo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine if any input row has been mapped to more than one P01 code where mapping was possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P01_duplicates = param_combo[(param_combo['P01'].notnull()) & (param_combo['rowID'].duplicated(keep=False))][['rowID','PARAM','MUNIT','MATRX','BASIS','METPT','Species','AphiaID','Note','P01','P01_label']]\n",
    "\n",
    "if len(P01_duplicates)>0:\n",
    "    print(\"\\nPotential duplicate P01 mappings in the DataFrame. Please check output below:\")\n",
    "    display(P01_duplicates)\n",
    "else:\n",
    "    print(\"No P01 duplicates for each input file row where a mapping was possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results of the ICES to NVS semantic model mapping to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete DataFrame\n",
    "full_results = os.path.join(results,'complete_output.csv')\n",
    "param_combo.to_csv(full_results, index=False)\n",
    "print(\"Full results set saved to: %s\" % full_results)\n",
    "\n",
    "x=len(param_combo[param_combo['P01_Code']!='-9'])\n",
    "y=len(param_combo[(param_combo['P01_Code']=='-9') & (param_combo['P01'].notnull())])\n",
    "z=len(param_combo[(param_combo['P01_Code']=='-9') & (param_combo['P01'].isnull())])\n",
    "\n",
    "# Split out those combinations that have already been mapped to P01 in the parameter set\n",
    "previous_P01 = os.path.join(results,'previous_P01.csv')\n",
    "param_combo[param_combo['P01_Code']!='-9'].to_csv(previous_P01, index=False)\n",
    "print(\"Subset of previously mapped P01 terms saved to: %s\" % full_results)\n",
    "\n",
    "# Retain those combinations that have not yet been mapped to P01\n",
    "mapped_P01 = os.path.join(results,'mapped_P01.csv')\n",
    "param_combo[(param_combo['P01_Code']=='-9') & (param_combo['P01'].notnull())].to_csv(mapped_P01, index=False)\n",
    "print(\"Subset of newly mapped P01 terms saved to: %s\" % mapped_P01)\n",
    "\n",
    "# Retain those combinations that have not yet been mapped to P01\n",
    "new_P01 = os.path.join(results,'new_P01.csv')\n",
    "param_combo[(param_combo['P01_Code']=='-9') & (param_combo['P01'].isnull())].to_csv(new_P01, index=False)\n",
    "print(\"Subset of possible P01 terms for creation saved to: %s\" % new_P01)\n",
    "    \n",
    "# Create summary information\n",
    "summary = pd.DataFrame([[\"Processing started:\" , (start.strftime('%Y-%m-%d %H:%M:%S'))],\n",
    "[\"Processing finished:\" , datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "[\"\" , \"\"],\n",
    "[\"Rows input:\", len(inputs)],\n",
    "[\"Rows output:\" , len(param_combo)],\n",
    "[\"Rows with P01 provided:\" , x],\n",
    "[\"Rows successfully mapped:\" , y],\n",
    "[\"Rows still to be mapped:\" , z],\n",
    "[\"Because:\", \"\"],\n",
    "[\"    Non-chemical PARAMs to be mapped:\" , len(alt_mapping)],\n",
    "[\"    New chemical substances (S27) for mapping:\" , len(S27new)],\n",
    "[\"    New matrix terms (S26) for creation:\" , len(S26new)],\n",
    "[\"    New biological entities (S25) for creation:\" , len(S25new)],\n",
    "[\"    Taxa discrepancies to be resolved:\" , len(taxa_discrepancy)]])\n",
    "\n",
    "print(\"\\nProcess results all saved to directory: %s\" % results)\n",
    "display(summary)\n",
    "\n",
    "if len(param_combo)!= len(inputs):\n",
    "    print(\"Check for duplicated results as number of rows out do not match number of rows in original file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
